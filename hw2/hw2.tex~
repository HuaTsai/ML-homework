\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{xcolor}
\numberwithin{equation}{section}
\DeclareMathOperator{\X}{\mathbf{X}}
\DeclareMathOperator{\x}{\mathbf{x}}
\DeclareMathOperator{\La}{\mathbf{\Lambda}}
\DeclareMathOperator{\m}{\mathbf{\mu}}
\DeclareMathOperator{\Si}{\mathbf{\Sigma}}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  numbers=none,
  showstringspaces=false,
  columns=flexible,
  basicstyle=\ttfamily,
  numberstyle=\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  backgroundcolor=\color{black!5}, % set backgroundcolor
}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
 
\title{Homework \#2}
\author{Shao Hua, Huang\\
ECM9032 - Machine Learning}

\begin{document}
\maketitle
Sorry, I haven't finished the whole homework, and I will hand in new version this week.
\section{Bayesian Inference for Gaussian (30\%)}
\begin{enumerate}
  \item Derive posterior distribution by the following equations.
    \begin{align*}
      p(\La|\X) & \propto \left[p(\La)\prod_{n=1}^{N-1}p(\x_n|\La)\right]p(\x_N|\La)\\
                & = p(\La)\prod_{n=1}^{N}p(\x_n|\La)\\
                & = \mathcal{W}(\La|W_0,\nu_0)\prod_{n=1}^{N}\mathcal{N}(\x_n|\m,\La^{-1})\\
                & = B_0|\La|^{\frac{\nu_0-D-1}{2}}\exp^{-\frac{1}{2}Tr(W_0^{-1}\La)}\times 
                    \frac{1}{(2\pi)^{\frac{ND}{2}}}|\La|^{\frac{N}{2}}\exp^{-\frac{1}{2}
                    \sum_{n=1}^{N}(\x_n-\m)^T\La(\x_n-\m)}\\
                & \propto |\La|^{\frac{\nu_0-D+N-1}{2}}\exp^{-\frac{1}{2}Tr(W_0^{-1}\La)}
                  \exp^{-\frac{1}{2}Tr(\La \mathbf{S})}\\
                & = |\La|^{\frac{\nu_0-D+N-1}{2}}\exp^{-\frac{1}{2}Tr(W_0^{-1}\La+\La\mathbf{S}))}
    \end{align*}
    where $$\mathbf{S} = \sum_{n=1}^{N}(\x_n-\m)(\x_n-\m)^T$$\\
    Therefore, we know that posterior is also a Wishart distribution, that is,
    $$p(\La|\X) = \mathcal{W}(\La|W_{\La},\nu_{\La})$$
    %where $W_{\La} = $ and $ $
\end{enumerate}
\section{Bayesian Linear Regression (30\%)}
See program hw2_2.py
\section{Logistic Regression (40\%)}

\end{document}
